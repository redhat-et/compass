{
  "_description": "Use case benchmark weights for model scoring",
  "_source": "Research-based weights for ranking models per use case",
  
  "use_case_weights": {
    
    "chatbot_conversational": {
      "description": "Real-time conversational chatbots (short prompts, short responses)",
      "weights": {
        "mmlu_pro": 0.30,
        "ifbench": 0.30,
        "hle": 0.20,
        "artificial_analysis_intelligence_index": 0.15,
        "gpqa": 0.05
      }
    },
    
    "code_completion": {
      "description": "Fast code completion/autocomplete (short prompts, short completions)",
      "weights": {
        "livecodebench": 0.35,
        "scicode": 0.30,
        "artificial_analysis_coding_index": 0.20,
        "terminalbench_hard": 0.10,
        "ifbench": 0.05
      }
    },
    
    "code_generation_detailed": {
      "description": "Detailed code generation with explanations (medium prompts, long responses)",
      "weights": {
        "livecodebench": 0.30,
        "scicode": 0.25,
        "ifbench": 0.20,
        "artificial_analysis_coding_index": 0.15,
        "hle": 0.10
      }
    },
    
    "translation": {
      "description": "Document translation (medium prompts, medium responses)",
      "weights": {
        "ifbench": 0.35,
        "mmlu_pro": 0.30,
        "hle": 0.20,
        "artificial_analysis_intelligence_index": 0.15
      }
    },
    
    "content_generation": {
      "description": "Content creation, marketing copy (medium prompts, medium responses)",
      "weights": {
        "mmlu_pro": 0.30,
        "hle": 0.25,
        "ifbench": 0.25,
        "artificial_analysis_intelligence_index": 0.20
      }
    },
    
    "summarization_short": {
      "description": "Short document summarization (medium prompts, short summaries)",
      "weights": {
        "hle": 0.30,
        "mmlu_pro": 0.25,
        "ifbench": 0.25,
        "artificial_analysis_intelligence_index": 0.20
      }
    },
    
    "document_analysis_rag": {
      "description": "RAG-based document Q&A (long prompts with context, medium responses)",
      "weights": {
        "lcr": 0.40,
        "mmlu_pro": 0.20,
        "hle": 0.20,
        "ifbench": 0.10,
        "tau2": 0.10
      }
    },
    
    "long_document_summarization": {
      "description": "Long document summarization (very long prompts, medium summaries)",
      "weights": {
        "lcr": 0.45,
        "mmlu_pro": 0.20,
        "hle": 0.20,
        "ifbench": 0.15
      }
    },
    
    "research_legal_analysis": {
      "description": "Research/legal document analysis (very long prompts, detailed analysis)",
      "weights": {
        "lcr": 0.40,
        "mmlu_pro": 0.25,
        "hle": 0.15,
        "gpqa": 0.10,
        "ifbench": 0.05,
        "tau2": 0.05
      }
    }
  },
  
  "available_benchmarks": [
    "mmlu_pro",
    "hle",
    "ifbench",
    "lcr",
    "gpqa",
    "livecodebench",
    "scicode",
    "terminalbench_hard",
    "tau2",
    "artificial_analysis_intelligence_index",
    "artificial_analysis_coding_index",
    "artificial_analysis_math_index"
  ],
  
  "custom_use_case_template": {
    "type": "custom",
    "name": "my_custom_task",
    "description": "Describe your use case",
    "weights": {
      "mmlu_pro": 0.25,
      "hle": 0.25,
      "ifbench": 0.25,
      "lcr": 0.25
    }
  }
}

