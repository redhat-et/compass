{
  "models": [
    {
      "model_id": "meta-llama/Llama-3.1-8B-Instruct",
      "name": "Llama 3.1 8B Instruct",
      "provider": "Meta",
      "family": "llama3",
      "size_parameters": "8B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "question_answering", "summarization"],
      "domain_specialization": ["general"],
      "license": "Llama 3.1 Community License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 16,
      "recommended_for": ["chatbot_conversational", "code_generation_detailed", "translation", "summarization_short", "content_generation"],
      "approval_status": "approved",
      "notes": "Excellent general-purpose model with strong instruction following"
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct",
      "name": "Llama 3.3 70B Instruct",
      "provider": "Meta",
      "family": "llama3",
      "size_parameters": "70B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "question_answering", "summarization", "reasoning"],
      "domain_specialization": ["general"],
      "license": "Llama 3.3 Community License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 80,
      "recommended_for": ["code_generation_detailed", "content_generation", "summarization_short", "document_analysis_rag", "long_document_summarization", "research_legal_analysis"],
      "approval_status": "approved",
      "notes": "High-performance model for complex reasoning tasks"
    },
    {
      "model_id": "mistralai/Mistral-Small-24B-Instruct-2501",
      "name": "Mistral Small 24B Instruct",
      "provider": "Mistral AI",
      "family": "mistral",
      "size_parameters": "24B",
      "context_length": 32768,
      "supported_tasks": ["chat", "instruction_following", "code_generation"],
      "domain_specialization": ["general", "code"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 48,
      "recommended_for": ["chatbot_conversational", "code_generation_detailed", "translation", "content_generation"],
      "approval_status": "approved",
      "notes": "Efficient model with strong code capabilities"
    },
    {
      "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "name": "Mixtral 8x7B Instruct",
      "provider": "Mistral AI",
      "family": "mixtral",
      "size_parameters": "8x7B",
      "context_length": 32768,
      "supported_tasks": ["chat", "instruction_following", "code_generation", "multilingual"],
      "domain_specialization": ["general", "code", "multilingual"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 80,
      "recommended_for": ["code_generation_detailed", "content_generation", "translation"],
      "approval_status": "approved",
      "notes": "Mixture-of-experts model with excellent multilingual support"
    },
    {
      "model_id": "ibm-granite/granite-3.1-8b-instruct",
      "name": "Granite 3.1 8B Instruct",
      "provider": "IBM",
      "family": "granite",
      "size_parameters": "8B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "summarization", "rag"],
      "domain_specialization": ["general", "enterprise"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 16,
      "recommended_for": ["chatbot_conversational", "document_analysis_rag", "summarization_short", "long_document_summarization"],
      "approval_status": "approved",
      "notes": "Enterprise-focused model with strong RAG capabilities"
    },
    {
      "model_id": "Qwen/Qwen2.5-7B-Instruct",
      "name": "Qwen 2.5 7B Instruct",
      "provider": "Alibaba Cloud",
      "family": "qwen",
      "size_parameters": "7B",
      "context_length": 131072,
      "supported_tasks": ["chat", "instruction_following", "code_generation", "multilingual"],
      "domain_specialization": ["general", "code", "multilingual"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 14,
      "recommended_for": ["chatbot_conversational", "code_generation_detailed", "translation"],
      "approval_status": "approved",
      "notes": "Strong multilingual and code capabilities with large context window"
    },
    {
      "model_id": "microsoft/phi-4",
      "name": "Phi-4",
      "provider": "Microsoft",
      "family": "phi",
      "size_parameters": "14B",
      "context_length": 16384,
      "supported_tasks": ["chat", "instruction_following", "reasoning", "code_generation"],
      "domain_specialization": ["general", "code"],
      "license": "MIT",
      "license_type": "permissive",
      "min_gpu_memory_gb": 28,
      "recommended_for": ["code_completion", "code_generation_detailed", "chatbot_conversational"],
      "approval_status": "approved",
      "notes": "Compact model with strong reasoning and code capabilities"
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "name": "Llama 4 Scout 17B Instruct",
      "provider": "Meta",
      "family": "llama4",
      "size_parameters": "17B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "reasoning"],
      "domain_specialization": ["general"],
      "license": "Llama 4 Community License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 34,
      "recommended_for": ["chatbot_conversational", "content_generation", "summarization_short"],
      "approval_status": "approved",
      "notes": "Next-generation Llama model with improved reasoning"
    },
    {
      "model_id": "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF",
      "name": "Llama 3.1 Nemotron 70B Instruct",
      "provider": "NVIDIA",
      "family": "llama3-nemotron",
      "size_parameters": "70B",
      "context_length": 128000,
      "supported_tasks": ["chat", "instruction_following", "reasoning", "summarization"],
      "domain_specialization": ["general"],
      "license": "NVIDIA Open Model License",
      "license_type": "permissive",
      "min_gpu_memory_gb": 80,
      "recommended_for": ["document_analysis_rag", "long_document_summarization", "research_legal_analysis", "content_generation"],
      "approval_status": "approved",
      "notes": "NVIDIA-optimized Llama variant with enhanced instruction following"
    },
    {
      "model_id": "Qwen/Qwen3-8B-FP8",
      "name": "Qwen3 8B FP8",
      "provider": "Alibaba Cloud",
      "family": "qwen",
      "size_parameters": "8B",
      "context_length": 131072,
      "supported_tasks": ["chat", "instruction_following", "code_generation", "multilingual"],
      "domain_specialization": ["general", "code", "multilingual"],
      "license": "Apache 2.0",
      "license_type": "permissive",
      "min_gpu_memory_gb": 8,
      "recommended_for": ["chatbot_conversational", "code_generation_detailed", "translation"],
      "approval_status": "approved",
      "notes": "FP8 quantized model for efficient inference with large context"
    }
  ],
  "gpu_types": [
    {
      "gpu_type": "L4",
      "memory_gb": 24,
      "compute_capability": "8.9",
      "typical_use_cases": ["inference"],
      "cost_per_hour_usd": 0.50,
      "availability": "high"
    },
    {
      "gpu_type": "A100-40",
      "memory_gb": 40,
      "compute_capability": "8.0",
      "typical_use_cases": ["inference", "training"],
      "cost_per_hour_usd": 3.00,
      "availability": "medium"
    },
    {
      "gpu_type": "A100-80",
      "memory_gb": 80,
      "compute_capability": "8.0",
      "typical_use_cases": ["inference", "training"],
      "cost_per_hour_usd": 4.50,
      "availability": "medium"
    },
    {
      "gpu_type": "H100",
      "memory_gb": 80,
      "compute_capability": "9.0",
      "typical_use_cases": ["inference", "training"],
      "cost_per_hour_usd": 8.00,
      "availability": "low"
    },
    {
      "gpu_type": "H200",
      "memory_gb": 141,
      "compute_capability": "9.0",
      "typical_use_cases": ["inference", "training"],
      "cost_per_hour_usd": 10.00,
      "availability": "low"
    }
  ]
}
